{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import backoff\n",
    "from bardapi import Bard\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "openai.api_key = \"\"\n",
    "#not shown for security purposes \n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_tries = 5)\n",
    "def get_answer_from_openai(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature = 1.0,\n",
    "        stop = None,\n",
    "        # max_tokens = 200\n",
    "    )\n",
    "    result = completion['choices'][0]['message']['content']\n",
    "    return result\n",
    "\n",
    "def get_answer_from_gpt4(file, prompt):\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature = 1.0,\n",
    "        stop = None,\n",
    "        # max_tokens = 200\n",
    "    )\n",
    "    result = completion['choices'][0]['message']['content']\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_answer_from_bard(prompt):\n",
    "    bard_token_list =  []\n",
    "    random.shuffle(bard_token_list)\n",
    "\n",
    "    for bard_token in bard_token_list:\n",
    "        try:\n",
    "            for i in range(5):\n",
    "                result = Bard(token=bard_token, timeout=30).get_answer(prompt)[\"content\"]\n",
    "                if ('Response Error:' not in result):\n",
    "                    return result\n",
    "        except:   \n",
    "            print('no') \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt4 use code edited to only input prompt, not file\n",
    "def get_answer_from_gpt4_promptonly(prompt):\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature = 1.0,\n",
    "        stop = None,\n",
    "        # max_tokens = 200\n",
    "    )\n",
    "    result = completion['choices'][0]['message']['content']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accommodation_type = 'airbnb'\n",
    "hotel = ['employee can speak english', 'golf course', 'parking lot', 'kind emloyee', 'romantic', 'big hotel', 'jacuzzi', 'renovated', 'family trip', 'spacious room', 'spa', 'discount', 'bar', 'contactless check in', 'cozy', 'air conditioning', 'late checkout', 'comfortable', 'infinity pool', 'honeymoon', 'safe', 'picture window', 'good airflow', 'in front of the bus station', 'good restaurants', 'kids club', 'close beach', 'shopping mall', 'city', 'resort', 'shuttle bus available', 'early check in', '24h front desk', 'small hotel', 'fast response', 'name value', 'hygenic', 'within walkable distance', 'breakfast', 'housekeeping every day', 'meticulous', 'amenities', 'cheap', 'close to the airport', 'sea view']\n",
    "airbnb = ['parking lot', 'friendly host', 'romantic', 'spacious', 'jacuzzi', 'renovated', 'family trip', 'couples', 'spacious rooms', 'spa', 'discount', 'bar', 'contactless check in', 'cozy', 'air conditioning', 'late check out', 'confortable', 'swimming pool', 'honeymoon', 'safe neighborhood', 'picture window', 'good airlow', 'close to the bus station', 'michelin restaurant', 'close to the beach', 'shopping', 'city', 'flexible check in times', 'hot tub', '24h support', 'small house', 'hygenic', 'within walking distance', 'kitchen', '썬베드', 'amenities', 'cheap', 'close to the airport', 'beach']\n",
    "japanese_ryokan = ['employee can speak english', 'parking lot', 'kind employee', 'romantic', 'japanese', 'hinoki', 'traditional', 'renovated', 'family trip', 'spacious room', 'spa', 'discount', 'contactless check in', 'cozy', 'air conditioning', 'late checkout', 'confortable', 'kaiseki', 'spa', 'hot pool', 'honeymoon', 'safe', 'tatami room', 'good airflow', 'in front of the bus station', 'good restaurants', 'shopping mall', 'city', 'shuttle bus available', 'early check in', '24h fron desk', 'hygenic', 'within walking distance', 'breakfast', 'clean', 'meticulous', 'like a hotel', 'cheap', 'close to the airport']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when changing accomodation types:\n",
    "1) change [accommodation_type] above to the desired accomodation_type (hotel, airbnb, japanese_ryokan, etc.)\n",
    "2) change [keywords] below to the list corresponding to the accomodation_type\n",
    "    (different keywords for different accomodation_types)\n",
    "3) if needed, add wanted keywords / remove keywords to produce a more focused output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "keywords = airbnb #change\n",
    "#change keywords based on desired accomodation\n",
    "\n",
    "@backoff.on_exception(backoff.expo, (openai.error.RateLimitError,\n",
    "                                     openai.error.APIError,\n",
    "                                     openai.error.ServiceUnavailableError,),\n",
    "                      max_tries=5, max_value = 60)\n",
    "def augment(number):\n",
    "    augment_output = []\n",
    "    \n",
    "    for n in tqdm(range(number)):\n",
    "        random.shuffle(keywords)\n",
    "        #keyword shuffle needed as code will return outputs with too many keywords at the front if not shuffles\n",
    "        keywords_joined = ','.join(keywords)\n",
    "\n",
    "        output = get_answer_from_gpt4_promptonly(keywords_joined + \"\\n Use two or more words in the list above to generate 1 question that a tourist using the \" + accommodation_type + \"database \" + accommodation_type +\"may have. The question must be generated with a question mark at the end.\")\n",
    "        #adding details to prompt will produce a more detailed output (ex: when searching for hotels --> instead of \"tourist using the..?\" use \"tourist planning to travel to Paris using the..?\")\n",
    "        output_data = [output]\n",
    "        augment_output.append(output_data)\n",
    "    return augment_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why we do not use '...produce n number of questions\" and only produce 1 question at a time:\n",
    "\n",
    "Increase in output quality (detail and less errors) if producing one question at a time like prompt above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv code (append mode)\n",
    "def save(data, filename):\n",
    "    with open(filename, 'a', newline = '', encoding='utf8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(repetition):\n",
    "\n",
    "save(augment(number of desired outputs), 'name of csv file you wish output to be saved to')\n",
    "\n",
    "range(repetition number, integer) X augment(integer) = total amount of questions produced \n",
    "(ex: range(4) and augment(500) = 4 x 500 = 2000)\n",
    "\n",
    "This is separated due to RateLimitError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    try:\n",
    "        save(augment(500), 'csv_file_name.csv')\n",
    "        print(\"waiting for next\")\n",
    "        time.sleep(60) #for RateLimitError, Increase time(seconds) if needed\n",
    "        print(\"resuming\")\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
